# VaseVL

This is the repository for the paper:
> **VaseVL: Multimodal Agent and Benchmark for Ancient Greek Pottery**
> 
> Jinchao Ge\*, [Zeyu Zhang](https://steve-zeyu-zhang.github.io)\*†, Biao Wu\*, Shiya Huang, Judith Bishop, Scott Mann, Gillian Shepherd, Ruicheng Zhang, Xuan Ren, Ling Chen, Meng Fang, Lingqiao Liu, [Yang Zhao](https://yangyangkiki.github.io/)\**
>
> \*Equal contribution. †Project lead. \**Corresponding author.
> 
> ### [Paper]() | [VaseVL Demo Website]() | [VaseVQ Dataset]() | [Papers With Code]() | [Papers With Code]() | [HF Paper]()
<center class ='img'>
<img title="VaseVL Pipeline" src="https://github.com/AIGeeksGroup/PathoHR/blob/main/PathoHR.png" width="100%">
</center>

## Citation

If you use any content of this repo for your work, please cite the following our paper:
```

```

## Introduction
We present VaseVL, a pioneering Multi-Modal Large Language Model (MLLM) agent for ancient Greek pottery, capable of understanding and analyzing visual and textual data to enhance cultural heritage preservation. To further support the research community, we introduce VaseVQA, a comprehensive Q&A benchmark for evaluating the reasoning and interpretative capabilities of MLLMs on ancient artifacts. The data has 31,773 multi-view vase images. From these, we select 11,693 as single-view images. The benchmark contains vision-language (VL) tasks of visual question answering. VaseVL achieves state-of-the-art performance in stylistic classification and historical attribution, providing critical tools for authentication, forgery detection, and digital archiving. Our final fine-tuning process for the 7B checkpoint uses 9,354 available vase data and finishes in 3~4 hours. Beyond academic contributions, VaseVL fosters global heritage conservation, mitigating cultural erosion and promoting public engagement with ancient Greek artistry.


## Demo UI Setup
You can set up your own conda virtual environment by running the commands below.
